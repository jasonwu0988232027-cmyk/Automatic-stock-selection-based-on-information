import streamlit as st
import yfinance as yf
import pandas as pd
import time
import random
import requests
import urllib3
from datetime import datetime

# --- åŸºç¤å®‰å…¨è¨­å®š ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(page_title="å°è‚¡å…¨å¸‚å ´æ’è¡Œæ¦œ - ç©©å®šç‰ˆ", layout="wide")

@st.cache_data(ttl=86400)
def get_all_tickers():
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/121.0.0.0'}
    try:
        res = requests.get(url, headers=headers, verify=False, timeout=15)
        res.encoding = 'big5'
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        return [f"{t.split('  ')[0]}.TW" for t in df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'] if len(t.split('  ')[0]) == 4]
    except:
        return ["2330.TW", "2317.TW", "2454.TW"]

def fetch_data_full(tickers):
    final_results = []
    batch_size = 15 
    p_bar = st.progress(0)
    status = st.empty()
    
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i : i + batch_size]
        status.text(f"â³ æ­£åœ¨åˆ†æå¸‚å ´è³‡é‡‘æµ: {i} / {len(tickers)}...")
        try:
            df = yf.download(batch, period="5d", group_by='ticker', threads=False)
            for t in batch:
                try:
                    t_df = df[t].dropna() if isinstance(df.columns, pd.MultiIndex) else df.dropna()
                    if not t_df.empty:
                        last = t_df.iloc[-1]
                        p, v = float(last['Close']), float(last['Volume'])
                        turnover = (p * v) / 100_000_000
                        if turnover > 0:
                            final_results.append({
                                "è‚¡ç¥¨ä»£è™Ÿ": t,
                                "æ”¶ç›¤åƒ¹": round(p, 2),
                                "æˆäº¤é‡(å¼µ)": int(v // 1000),
                                "æˆäº¤é‡‘é¡(å„„)": round(turnover, 2),
                                "æˆäº¤å€¼æŒ‡æ¨™": round(turnover, 2)
                            })
                except: continue
        except: pass
        time.sleep(random.uniform(1.0, 2.0))
        p_bar.progress(min((i + batch_size) / len(tickers), 1.0))
    status.text("âœ… æ•¸æ“šæƒæå®Œæˆ")
    return pd.DataFrame(final_results)

# --- ä¸» UI ---
st.title("ğŸ“Š å°è‚¡æˆäº¤å€¼ Top 100 æŒ‡æ¨™æ’è¡Œæ¦œ")

if 'last_run' not in st.session_state: st.session_state.last_run = 0
time_diff = time.time() - st.session_state.last_run

if st.button("ğŸš€ é–‹å§‹åˆ†æå…¨å¸‚å ´æŒ‡æ¨™", type="primary"):
    if time_diff < 300:
        st.error(f"ğŸ›‘ ç³»çµ±å†·å»ä¸­ï¼Œè«‹ç­‰å¾… {int(300 - time_diff)} ç§’ã€‚")
    else:
        st.session_state.last_run = time.time()
        tickers = get_all_tickers()
        st.write(f"ğŸ” æœå°‹åˆ° {len(tickers)} éš»è‚¡ç¥¨ï¼Œè¨ˆç®—ä¸­...")
        
        df_final = fetch_data_full(tickers)
        
        if not df_final.empty:
            top_100 = df_final.sort_values("æˆäº¤é‡‘é¡(å„„)", ascending=False).head(100).reset_index(drop=True)
            top_100.index += 1
            
            st.subheader("ğŸ† ä»Šæ—¥æˆäº¤å€¼ Top 100")
            
            # --- å®‰å…¨é¡¯ç¤ºé‚è¼¯ ---
            try:
                # å˜—è©¦ä½¿ç”¨å¸¶é¡è‰²çš„æ¨£å¼
                styled_df = top_100.style.format({
                    "æ”¶ç›¤åƒ¹": "{:.2f}",
                    "æˆäº¤é‡‘é¡(å„„)": "{:.2f}",
                    "æˆäº¤å€¼æŒ‡æ¨™": "{:.2f}"
                }).background_gradient(subset=['æˆäº¤å€¼æŒ‡æ¨™'], cmap='Oranges')
                st.dataframe(styled_df, use_container_width=True)
            except ImportError:
                # å¦‚æœç¼ºå°‘ matplotlibï¼Œå‰‡é¡¯ç¤ºæ™®é€šè¡¨æ ¼
                st.warning("æç¤ºï¼šå®‰è£ matplotlib å¯å•Ÿç”¨è¡¨æ ¼é¡è‰²æ¼¸å±¤ã€‚")
                st.dataframe(top_100, use_container_width=True)
            
            csv = top_100.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ä¸‹è¼‰æ­¤å ±è¡¨ (CSV)", data=csv, file_name="Stock_Indicator_Rank.csv")
        else:
            st.error("æƒæçµæœç‚ºç©ºã€‚")
