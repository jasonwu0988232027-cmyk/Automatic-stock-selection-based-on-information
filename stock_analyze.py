import streamlit as st
import yfinance as yf
import pandas as pd
import time
import random
import requests
import urllib3
from datetime import datetime

# --- åŸºç¤å®‰å…¨è¨­å®š ---
# é—œé–‰ SSL é©—è­‰è­¦å‘Š (é‡å°è­‰äº¤æ‰€ç¶²ç«™)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Streamlit é é¢é…ç½®
st.set_page_config(page_title="å°è‚¡æˆäº¤å€¼ Top 100 è‡ªå‹•æ’è¡Œæ¦œ", layout="wide")

# å¸¸æ•¸è¨­å®š
COOLDOWN_SECONDS = 300  # å…©æ¬¡å¤§æƒæä¹‹é–“çš„å¼·åˆ¶å†·å»æ™‚é–“ (5 åˆ†é˜)

# --- 1. è‡ªå‹•ç²å–å°è‚¡æ¸…å–® (å« SSL éŒ¯èª¤ä¿®æ­£) ---
@st.cache_data(ttl=86400)
def get_all_taiwan_tickers():
    """å¾è­‰äº¤æ‰€ç²å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨ä»£ç¢¼"""
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        # verify=False è§£æ±º SSL: CERTIFICATE_VERIFY_FAILED éŒ¯èª¤
        response = requests.get(url, headers=headers, timeout=15, verify=False)
        response.encoding = 'big5'
        
        tables = pd.read_html(response.text)
        df = tables[0]
        df.columns = df.iloc[0]
        
        # ç¯©é¸ä»£è™Ÿæ¸…å–® (æ‰¾å‡ºæœ‰ '  ' åˆ†éš”çš„è¡Œï¼Œä¸¦å–å‰ 4 ä½ç‚ºç´”æ•¸å­—è€…)
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        raw_tickers = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split("  ").str[0]
        
        clean_tickers = [f"{t}.TW" for t in raw_tickers if t.isdigit() and len(t) == 4]
        return clean_tickers
    except Exception as e:
        st.warning(f"è‡ªå‹•æŠ“å–æ¸…å–®å¤±æ•— ({e})ï¼Œæ”¹ç”¨é è¨­æ ¸å¿ƒæŒè‚¡æ¸…å–®ã€‚")
        return ["2330.TW", "2317.TW", "2454.TW", "2308.TW", "2382.TW", "2881.TW", "2882.TW", "2603.TW"]

# --- 2. æ‰¹é‡æŠ“å–æˆäº¤æ•¸æ“š (å«é˜²å°é–å»¶é²) ---
def fetch_stock_data(tickers):
    """åˆ†æ‰¹ä¸‹è¼‰æ•¸æ“šï¼Œé™ä½è¢« Yahoo Finance å°é–çš„é¢¨éšª"""
    all_data = []
    batch_size = 50 
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i : i + batch_size]
        status_text.text(f"ğŸš€ æ­£åœ¨åˆ†ææ•¸æ“š: {i} / {len(tickers)} éš»è‚¡ç¥¨...")
        
        try:
            # æ‰¹é‡æŠ“å–ç•¶æ—¥æ•¸æ“š
            df = yf.download(batch, period="1d", group_by='ticker', silent=True, threads=True)
            
            for ticker in batch:
                if ticker in df and not df[ticker].empty:
                    last_price = df[ticker]['Close'].iloc[-1]
                    volume = df[ticker]['Volume'].iloc[-1]
                    turnover = last_price * volume # æˆäº¤å€¼
                    
                    if not pd.isna(turnover) and turnover > 0:
                        all_data.append({
                            "è‚¡ç¥¨ä»£è™Ÿ": ticker,
                            "æ”¶ç›¤åƒ¹": round(last_price, 2),
                            "æˆäº¤é‡(å¼µ)": int(volume // 1000),
                            "æˆäº¤é‡‘é¡(å„„)": round(turnover / 100_000_000, 3)
                        })
        except:
            continue
            
        # é—œéµé˜²å°é–ï¼šæ¯çµ„è«‹æ±‚å¾Œéš¨æ©Ÿä¼‘æ¯ 2-4 ç§’
        time.sleep(random.uniform(2, 4))
        progress_bar.progress(min((i + batch_size) / len(tickers), 1.0))
        
    status_text.text("âœ… è³‡æ–™åˆ†æå®Œæˆï¼")
    return pd.DataFrame(all_data)

# --- 3. Streamlit ä¸»ä»‹é¢ ---
st.title("ğŸ“Š å°è‚¡ç•¶æ—¥æˆäº¤å€¼ Top 100")
st.info("é»æ“Šä¸‹æ–¹æŒ‰éˆ•é–‹å§‹æƒæå…¨å°è‚¡å¸‚å ´ã€‚ç‚ºäº†ä¿è­·æ‚¨çš„ IPï¼Œæ¯æ¬¡åŸ·è¡Œå¾Œæœ‰ 5 åˆ†é˜å†·å»æ™‚é–“ã€‚")

# åˆå§‹åŒ– Session State è¨˜éŒ„é‹è¡Œæ™‚é–“
if 'last_run' not in st.session_state:
    st.session_state.last_run = 0

now = time.time()
time_left = COOLDOWN_SECONDS - (now - st.session_state.last_run)

if st.button("é–‹å§‹è‡ªå‹•æŸ¥è©¢", type="primary"):
    if time_left > 0:
        st.error(f"è«‹ç¨å€™å†è©¦ï¼å†·å»æ™‚é–“é‚„å‰© {int(time_left)} ç§’ã€‚")
    else:
        st.session_state.last_run = now
        
        with st.status("æ­£åœ¨åŸ·è¡Œè‡ªå‹•åŒ–æµç¨‹...", expanded=True) as status:
            st.write("ğŸ” æ­£åœ¨å‘è­‰äº¤æ‰€ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...")
            ticker_list = get_all_taiwan_tickers()
            st.write(f"å·²è­˜åˆ¥ {len(ticker_list)} éš»æœ‰æ•ˆè‚¡ç¥¨ä»£ç¢¼ã€‚")
            
            st.write("â³ æ­£åœ¨è¨ˆç®—å„è‚¡æˆäº¤å€¼ (å«é˜²å°é–å»¶é²æ©Ÿåˆ¶)...")
            final_df = fetch_stock_data(ticker_list)
            status.update(label="æ•¸æ“šè™•ç†å®Œç•¢ï¼", state="complete", expanded=False)
        
        if not final_df.empty:
            # æ’åºä¸¦å–å‰ 100
            top_100 = final_df.sort_values(by="æˆäº¤é‡‘é¡(å„„)", ascending=False).head(100).reset_index(drop=True)
            top_100.index += 1 # æ’åå¾ 1 é–‹å§‹
            
            st.subheader(f"ğŸ† ä»Šæ—¥æˆäº¤å€¼æ’è¡Œæ¦œ (å‰ 100 å)")
            st.dataframe(top_100, use_container_width=True)
            
            # ç°¡å–®è¦–è¦ºåŒ–
            st.bar_chart(data=top_100.head(10).set_index("è‚¡ç¥¨ä»£è™Ÿ")["æˆäº¤é‡‘é¡(å„„)"])
            
            # æä¾› CSV ä¸‹è¼‰
            csv_data = top_100.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±è¡¨ (CSV)", data=csv_data, file_name="TW_Stock_Top100.csv", mime="text/csv")
        else:
            st.error("æƒæçµæœç‚ºç©ºï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–ç¨å¾Œå†è©¦ã€‚")

st.divider()
st.caption(f"æ•¸æ“šæ›´æ–°æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ•¸æ“šæºï¼šYahoo Finance / TWSE")
