import streamlit as st
import yfinance as yf
import pandas as pd
import time
import random
import requests
import urllib3
from datetime import datetime

# --- åŸºç¤å®‰å…¨è¨­å®š ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(page_title="å°è‚¡æˆäº¤å€¼ Top 100 è‡ªå‹•æ’è¡Œæ¦œ", layout="wide")

# å¸¸æ•¸è¨­å®š
COOLDOWN_SECONDS = 300 

# æ¨¡æ“¬å¤šå€‹ç€è¦½å™¨æ¨™é ­ï¼Œé™ä½è¢«å°é–æ©Ÿç‡
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]

@st.cache_data(ttl=86400)
def get_all_taiwan_tickers():
    """å¾è­‰äº¤æ‰€ç²å–æ‰€æœ‰ä¸Šå¸‚è‚¡ç¥¨ä»£ç¢¼"""
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {'User-Agent': random.choice(USER_AGENTS)}
    try:
        response = requests.get(url, headers=headers, timeout=15, verify=False)
        response.encoding = 'big5'
        tables = pd.read_html(response.text)
        df = tables[0]
        df.columns = df.iloc[0]
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        raw_tickers = df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.split("  ").str[0]
        clean_tickers = [f"{t}.TW" for t in raw_tickers if t.isdigit() and len(t) == 4]
        return clean_tickers
    except Exception as e:
        st.warning(f"ç²å–æ¸…å–®å¤±æ•—: {e}")
        return ["2330.TW", "2317.TW", "2454.TW", "2308.TW", "2382.TW", "2881.TW"]

def fetch_stock_data(tickers):
    """å¼·åŒ–ç‰ˆæ•¸æ“šæŠ“å–ï¼šç¸®å° Batch ä¸¦å¢åŠ éŒ¯èª¤è·³éæ©Ÿåˆ¶"""
    all_data = []
    # ç¸®å° Batch è¦æ¨¡è‡³ 20ï¼Œé€™å°ç©©å®šæ€§éå¸¸æœ‰å¹«åŠ©
    batch_size = 20 
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i : i + batch_size]
        status_text.text(f"ğŸš€ æ­£åœ¨åˆ†ææ•¸æ“š: {i} / {len(tickers)} éš»è‚¡ç¥¨...")
        
        try:
            # åŠ å…¥ threads=False æœ‰æ™‚åœ¨é›²ç«¯ç’°å¢ƒåè€Œæ›´ç©©å®š
            df = yf.download(
                batch, 
                period="1d", 
                group_by='ticker', 
                silent=True, 
                threads=True,
                timeout=20
            )
            
            for ticker in batch:
                try:
                    # åˆ¤æ–·å¤šå€‹è‚¡ç¥¨è¿”å›çš„ DataFrame çµæ§‹
                    target_df = df[ticker] if len(batch) > 1 else df
                    
                    if not target_df.empty and 'Close' in target_df:
                        last_price = target_df['Close'].iloc[-1]
                        volume = target_df['Volume'].iloc[-1]
                        turnover = last_price * volume
                        
                        if not pd.isna(turnover) and turnover > 0:
                            all_data.append({
                                "è‚¡ç¥¨ä»£è™Ÿ": ticker,
                                "æ”¶ç›¤åƒ¹": round(float(last_price), 2),
                                "æˆäº¤é‡(å¼µ)": int(volume // 1000),
                                "æˆäº¤é‡‘é¡(å„„)": round(float(turnover / 100_000_000), 3)
                            })
                except:
                    continue
        except Exception as e:
            # å¦‚æœæ•´çµ„å¤±æ•—ï¼Œç•¥éä¸¦ç¹¼çºŒä¸‹ä¸€çµ„
            continue
            
        # å¢åŠ å»¶é²æ™‚é–“ç¢ºä¿ä¸è¢«å°é–
        time.sleep(random.uniform(1.5, 3.0))
        progress_bar.progress(min((i + batch_size) / len(tickers), 1.0))
        
    status_text.text("âœ… è³‡æ–™åˆ†æå®Œæˆï¼")
    return pd.DataFrame(all_data)

# --- ä¸»ä»‹é¢ ---
st.title("ğŸ“Š å°è‚¡ç•¶æ—¥æˆäº¤å€¼ Top 100")

if 'last_run' not in st.session_state:
    st.session_state.last_run = 0

now = time.time()
time_left = COOLDOWN_SECONDS - (now - st.session_state.last_run)

if st.button("é–‹å§‹è‡ªå‹•æŸ¥è©¢", type="primary"):
    if time_left > 0:
        st.error(f"è«‹ç¨å€™å†è©¦ï¼å†·å»æ™‚é–“é‚„å‰© {int(time_left)} ç§’ã€‚")
    else:
        st.session_state.last_run = now
        ticker_list = get_all_taiwan_tickers()
        
        # åˆæ¬¡ç¯©é¸ï¼šç‚ºäº†æ¸¬è©¦ç©©å®šæ€§ï¼Œå¯ä»¥å…ˆå–å‰ 300 éš»ï¼ˆæˆäº¤é‡é€šå¸¸é›†ä¸­åœ¨å‰ç«¯ï¼‰
        # å¦‚æœè¦å…¨æƒæï¼Œè«‹è¨»è§£æ‰ä¸‹é¢é€™è¡Œ
        # ticker_list = ticker_list[:300] 
        
        final_df = fetch_stock_data(ticker_list)
        
        if not final_df.empty:
            top_100 = final_df.sort_values(by="æˆäº¤é‡‘é¡(å„„)", ascending=False).head(100).reset_index(drop=True)
            top_100.index += 1
            
            st.subheader(f"ğŸ† ä»Šæ—¥æˆäº¤å€¼æ’è¡Œæ¦œ (å‰ 100 å)")
            st.dataframe(top_100, use_container_width=True)
            
            st.bar_chart(data=top_100.head(10).set_index("è‚¡ç¥¨ä»£è™Ÿ")["æˆäº¤é‡‘é¡(å„„)"])
            
            csv_data = top_100.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ ä¸‹è¼‰å®Œæ•´å ±è¡¨ (CSV)", data=csv_data, file_name="TW_Stock_Top100.csv", mime="text/csv")
        else:
            st.error("âŒ æƒæçµæœç‚ºç©ºã€‚åŸå› å¯èƒ½æ˜¯ï¼š1.ç›®å‰éé–‹ç›¤æ™‚é–“ä¸”ç„¡æ˜¨æ—¥æ•¸æ“š 2.Yahoo Finance æš«æ™‚é™åˆ¶æ‚¨çš„ IPã€‚è«‹ç­‰å¾…å†·å»æ™‚é–“çµæŸå¾Œå†è©¦ã€‚")

st.divider()
st.caption(f"æ•¸æ“šæ›´æ–°æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | æ•¸æ“šæºï¼šYahoo Finance / TWSE")
