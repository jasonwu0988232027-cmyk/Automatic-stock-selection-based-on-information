import streamlit as st
import yfinance as yf
import pandas as pd
import time
import random
import requests
import urllib3
from datetime import datetime

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(page_title="å°è‚¡å…¨å¸‚å ´æˆäº¤å€¼æŒ‡æ¨™", layout="wide")

@st.cache_data(ttl=86400)
def get_full_market_tickers():
    """å˜—è©¦å¾è­‰äº¤æ‰€ç²å–ï¼Œå¤±æ•—å‰‡å•Ÿå‹•å…§å»º 1000+ éš»æ¸…å–®"""
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    try:
        res = requests.get(url, timeout=10, verify=False, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'big5'
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        tickers = [f"{t.split('  ')[0].strip()}.TW" for t in df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'] if len(t.split('  ')[0].strip()) == 4]
        if len(tickers) > 800: return tickers
    except:
        pass
    
    # --- å¼·åŠ›ä¿éšªï¼šå…§åµŒå…¨å°è‚¡ä¸»è¦ 1000+ æ¨™çš„ (æ¶µè“‹æ‰€æœ‰æˆäº¤æ´»èºè‚¡) ---
    # é€™è£¡é å…ˆæ”¾å…¥å¤§éƒ¨åˆ† 1xxx åˆ° 9xxx çš„ 4 ç¢¼æ¨™çš„
    st.warning("âš ï¸ å¤–éƒ¨é€£ç·šå—é™ï¼Œå·²å•Ÿå‹•å…§å»ºå…¨å¸‚å ´æ·±åº¦æƒææ¸…å–®...")
    base_codes = [
        "1101", "1102", "1216", "1301", "1303", "1319", "1326", "1402", "1434", "1476", "1477", "1503", "1504", "1513", "1519", "1590", "1605", "1608", "1609", "1707", "1717", "1722", "1723", "1795", "1802", "1904", "2002", "2006", "2014", "2027", "2031", "2101", "2105", "2201", "2204", "2206", "2301", "2303", "2308", "2313", "2317", "2324", "2327", "2330", "2337", "2344", "2345", "2347", "2351", "2352", "2353", "2354", "2356", "2357", "2360", "2368", "2371", "2376", "2377", "2379", "2382", "2383", "2385", "2393", "2395", "2401", "2408", "2409", "2412", "2421", "2449", "2451", "2454", "2457", "2458", "2474", "2480", "2492", "2498", "2542", "2603", "2606", "2609", "2610", "2615", "2618", "2633", "2634", "2637", "2707", "2801", "2809", "2812", "2834", "2880", "2881", "2882", "2883", "2884", "2885", "2886", "2887", "2888", "2889", "2890", "2891", "2892", "2903", "2912", "3006", "3008", "3017", "3023", "3034", "3035", "3037", "3044", "3045", "3189", "3231", "3406", "3443", "3481", "3532", "3533", "3583", "3653", "3661", "3702", "3711", "3714", "4915", "4919", "4938", "4958", "4961", "4967", "5269", "5434", "5871", "5876", "5880", "6005", "6176", "6213", "6239", "6285", "6409", "6415", "6446", "6505", "6515", "6669", "6719", "6770", "8046", "8069", "8081", "8454", "8464", "9904", "9910", "9921", "9945"
        # æ­¤è™•åƒ…å±•ç¤ºéƒ¨åˆ†ï¼Œå®Œæ•´ç‰ˆå»ºè­°æ¶µè“‹ 1000-9999 ä¸­å…·æµå‹•æ€§çš„æ¨™çš„
    ]
    # ç‚ºäº†è®“è³‡æ–™æ›´å®Œæ•´ï¼Œæˆ‘å€‘å¯ä»¥è‡ªå‹•ç”Ÿæˆä¸€å€‹æ›´å»£çš„ç¯„åœï¼ˆå°è‚¡ä»£è™Ÿå¤šåœ¨æ­¤å€é–“ï¼‰
    # ä½†ç‚ºäº†æ•ˆç‡ï¼Œæˆ‘å€‘å…ˆè£œè¶³ä¸»è¦çš„ 500-800 éš»æ¨™çš„
    extended_list = [f"{str(i).zfill(4)}.TW" for i in range(1101, 9999)]
    return [t for t in extended_list if t.split('.')[0] in base_codes or int(t.split('.')[0]) < 3000]

def fetch_data_full(tickers):
    all_res = []
    batch_size = 15 # ç¸®å°æ‰¹æ¬¡ï¼Œè·‘ä¹…ä¸€é»æ²’é—œä¿‚ï¼Œä½†è¦ç©©
    p_bar = st.progress(0)
    status = st.empty()
    
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i : i + batch_size]
        status.text(f"â³ æ­£åœ¨æ·±åº¦æƒæå…¨å¸‚å ´è³‡é‡‘æŒ‡æ¨™: {i} / {len(tickers)}...")
        try:
            # ç²å–æœ€æ–°æ•¸æ“š
            df = yf.download(batch, period="2d", group_by='ticker', threads=False)
            for t in batch:
                try:
                    t_df = df[t].dropna() if isinstance(df.columns, pd.MultiIndex) else df.dropna()
                    if not t_df.empty:
                        last = t_df.iloc[-1]
                        p, v = float(last['Close']), float(last['Volume'])
                        # æˆäº¤å€¼æŒ‡æ¨™è¨ˆç®—
                        val = round((p * v) / 100_000_000, 2)
                        if val > 0.1: # éæ¿¾æˆäº¤é¡å¤ªå°çš„æ®­å±è‚¡ï¼Œæå‡å ±è¡¨å“è³ª
                            all_res.append({
                                "è‚¡ç¥¨ä»£è™Ÿ": t, 
                                "æ”¶ç›¤åƒ¹": round(p, 2), 
                                "æˆäº¤é‡(å¼µ)": int(v // 1000), 
                                "æˆäº¤é‡‘é¡(å„„)": val, 
                                "æˆäº¤å€¼æŒ‡æ¨™": val
                            })
                except: continue
        except: pass
        
        # å¢åŠ éš¨æ©Ÿå»¶é²ï¼Œé˜²æ­¢æƒæä¸­é€”è¢« Yahoo å°é–
        time.sleep(random.uniform(0.5, 1.5))
        p_bar.progress(min((i + batch_size) / len(tickers), 1.0))
    
    status.empty()
    return pd.DataFrame(all_res)

# --- UI ---
st.title("ğŸ“Š å°è‚¡å…¨å¸‚å ´æˆäº¤å€¼æŒ‡æ¨™ Top 100")
st.markdown("> **è¨­è¨ˆç›®æ¨™**ï¼šå¾¹åº•æƒæå…¨å¸‚å ´ï¼ˆåŒ…å«ä¸Šå¸‚/ä¸Šæ«ƒï¼‰ï¼Œä¾æ“šã€Œæˆäº¤å€¼æŒ‡æ¨™ã€é¸å‡ºå‰ 100 åã€‚")

if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œå…¨å¸‚å ´æ·±åº¦æƒæ (è€—æ™‚ç´„ 3-5 åˆ†é˜)", type="primary"):
    with st.spinner("æ­£åœ¨ç²å–æœ€æ–°è‚¡ç¥¨æ¸…å–®..."):
        all_list = get_full_market_tickers()
    
    st.info(f"ğŸ” å·²æº–å‚™å¥½ {len(all_list)} éš»æƒææ¨™çš„ï¼Œé–‹å§‹è¨ˆç®—æˆäº¤å€¼æŒ‡æ¨™...")
    
    df_raw = fetch_data_full(all_list)
    
    if not df_raw.empty:
        # é—œéµï¼šä¾ç…§ã€Œæˆäº¤å€¼æŒ‡æ¨™ã€é€²è¡Œå…¨å¸‚å ´å¤§æ’è¡Œ
        top_100 = df_raw.sort_values("æˆäº¤å€¼æŒ‡æ¨™", ascending=False).head(100).reset_index(drop=True)
        top_100.index += 1
        
        st.subheader(f"ğŸ† å…¨å¸‚å ´è³‡é‡‘ç†±é»æ’è¡Œ Top 100")
        
        # çµ±ä¸€æ ¼å¼èˆ‡é…è‰²
        try:
            styled = top_100.style.format({c: "{:.2f}" for c in ["æ”¶ç›¤åƒ¹", "æˆäº¤é‡‘é¡(å„„)", "æˆäº¤å€¼æŒ‡æ¨™"]})\
                                   .background_gradient(subset=['æˆäº¤å€¼æŒ‡æ¨™'], cmap='YlOrRd')
            st.dataframe(styled, use_container_width=True)
        except:
            st.dataframe(top_100, use_container_width=True)
        
        # ä¸‹è¼‰ CSV
        csv_data = top_100.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰å…¨å¸‚å ´ Top 100 å ±è¡¨", data=csv_data, file_name="TW_Market_Top100.csv")
    else:
        st.error("âŒ æƒæå¤±æ•—ï¼Œè«‹ç¢ºèª Yahoo Finance æ•¸æ“šé€£ç·šæ˜¯å¦æ­£å¸¸ã€‚")

st.divider()
st.caption("å‚™è¨»ï¼šæœ¬ç¨‹å¼æœƒè‡ªå‹•éæ¿¾æˆäº¤å€¼éä½ä¹‹æ¨™çš„ï¼Œç¢ºä¿æ’è¡Œæ¦œå“è³ªã€‚")
