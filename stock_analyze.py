import streamlit as st
import yfinance as yf
import pandas as pd
import time
import random
import requests
import urllib3
from datetime import datetime

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(page_title="å°è‚¡æˆäº¤å€¼æŒ‡æ¨™-è¶…ç©©ç‰ˆ", layout="wide")

@st.cache_data(ttl=86400)
def get_all_tickers_hybrid():
    """å¤šé‡å‚™æ´æ©Ÿåˆ¶ï¼šç¢ºä¿åå–®ç²å–ä¸å¤±æ•—"""
    
    # --- ä¾†æº 1: è­‰äº¤æ‰€å®˜ç¶² ---
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/121.0.0.0'}
    try:
        res = requests.get(url, headers=headers, timeout=10, verify=False)
        res.encoding = 'big5'
        df = pd.read_html(res.text)[0]
        df.columns = df.iloc[0]
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        tickers = [f"{t.split('  ')[0].strip()}.TW" for t in df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'] if len(t.split('  ')[0].strip()) == 4]
        if len(tickers) > 500: return tickers
    except:
        pass

    # --- ä¾†æº 2: GitHub å‚™ç”¨æ¸…å–® (ç©©å®šæ€§æœ€é«˜) ---
    try:
        # ä½¿ç”¨å¸¸è¦‹çš„é–‹æº CSV ä½œç‚ºæ¸…å–®ä¾†æº
        backup_df = pd.read_csv("https://raw.githubusercontent.com/yishuen/taiwan-stock-list/master/stock_list.csv")
        tickers = [f"{str(code).strip()}.TW" for code in backup_df['code'] if len(str(code).strip()) == 4]
        if len(tickers) > 100: return tickers
    except:
        pass

    # --- ä¾†æº 3: å…§å»ºæ ¸å¿ƒ Top 100 æ¬Šå€¼è‚¡ (ä¿éšªåº•ç·š) ---
    st.warning("âš ï¸ æ­£å¾å…§å»ºæ ¸å¿ƒåå–®åŠ è¼‰ (å¯èƒ½éå…¨å¸‚å ´)...")
    core_list = [
        "2330.TW", "2317.TW", "2454.TW", "2308.TW", "2382.TW", "2603.TW", "2881.TW", "2882.TW", 
        "3711.TW", "2412.TW", "2303.TW", "2886.TW", "2891.TW", "1301.TW", "1303.TW", "3008.TW",
        # ... (æ­¤è™•ç°¡ç•¥ï¼Œå¯¦éš›ä¸ŠæœƒåŒ…å«æ›´å¤š)
    ]
    return core_list

def fetch_data(tickers):
    all_res = []
    batch_size = 15
    p_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i : i + batch_size]
        status_text.text(f"ğŸ“Š æ­£åœ¨åˆ†ææˆäº¤å€¼æŒ‡æ¨™: {i} / {len(tickers)}...")
        try:
            df = yf.download(batch, period="5d", group_by='ticker', threads=False)
            for t in batch:
                try:
                    t_df = df[t].dropna() if isinstance(df.columns, pd.MultiIndex) else df.dropna()
                    if not t_df.empty:
                        last = t_df.iloc[-1]
                        p, v = float(last['Close']), float(last['Volume'])
                        val = round((p * v) / 100_000_000, 2)
                        if val > 0:
                            all_res.append({
                                "è‚¡ç¥¨ä»£è™Ÿ": t, 
                                "æ”¶ç›¤åƒ¹": round(p, 2), 
                                "æˆäº¤é‡(å¼µ)": int(v // 1000), 
                                "æˆäº¤é‡‘é¡(å„„)": val, 
                                "æˆäº¤å€¼æŒ‡æ¨™": val
                            })
                except: continue
        except: pass
        time.sleep(random.uniform(1.0, 2.0))
        p_bar.progress(min((i + batch_size) / len(tickers), 1.0))
    return pd.DataFrame(all_res)

# --- UI ---
st.title("ğŸ“Š å°è‚¡æˆäº¤å€¼æŒ‡æ¨™ Top 100 æ’è¡Œæ¦œ")
st.caption("æ”¯æ´å¤šé‡æ•¸æ“šå‚™æ´ï¼Œç¢ºä¿æƒæä¸ä¸­æ–·ã€‚")

if st.button("ğŸš€ åŸ·è¡Œå…¨å¸‚å ´æƒæ", type="primary"):
    with st.spinner("æ­£åœ¨ç²å–å°è‚¡æ¸…å–® (å«å‚™æ´ä¾†æº)..."):
        all_list = get_all_tickers_hybrid()
    
    if all_list:
        st.write(f"ğŸ” æ‰¾åˆ° {len(all_list)} éš»æ¨™çš„ï¼Œé–‹å§‹æƒæ Yahoo Finance æ•¸æ“š...")
        df_raw = fetch_data(all_list)
        
        if not df_raw.empty:
            # ä¾æŒ‡æ¨™æ’åºå–å‰ 100
            top_100 = df_raw.sort_values("æˆäº¤å€¼æŒ‡æ¨™", ascending=False).head(100).reset_index(drop=True)
            top_100.index += 1
            
            st.subheader(f"ğŸ† ä»Šæ—¥è³‡é‡‘ç†±é» Top 100")
            
            # å¼·åˆ¶å…©ä½å°æ•¸ä¸¦ä¸Šè‰² (è‹¥ matplotlib ç¼ºå¤±æœƒè‡ªå‹•é€€å›æ™®é€šè¡¨æ ¼)
            try:
                styled = top_100.style.format({c: "{:.2f}" for c in ["æ”¶ç›¤åƒ¹", "æˆäº¤é‡‘é¡(å„„)", "æˆäº¤å€¼æŒ‡æ¨™"]})\
                                       .background_gradient(subset=['æˆäº¤å€¼æŒ‡æ¨™'], cmap='YlOrRd')
                st.dataframe(styled, use_container_width=True)
            except:
                st.dataframe(top_100, use_container_width=True)
            
            st.download_button("ğŸ“¥ ä¸‹è¼‰å ±è¡¨ CSV", data=top_100.to_csv(index=False).encode('utf-8-sig'), file_name="Top100_Indicator.csv")
        else:
            st.error("âŒ ç„¡æ³•æŠ“å– Yahoo æ•¸æ“šï¼Œå¯èƒ½æ˜¯ IP è¢«æš«æ™‚é™åˆ¶ã€‚")
    else:
        st.error("âŒ æ‰€æœ‰æ¸…å–®ç²å–ç®¡é“å‡å¤±æ•ˆï¼Œè«‹ç¢ºèªç¶²è·¯é€£ç·šã€‚")
