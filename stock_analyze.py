import streamlit as st
import yfinance as yf
import pandas as pd
import time
import random
import requests
import urllib3
from datetime import datetime

# --- å®‰å…¨èˆ‡åŸºç¤é…ç½® ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
st.set_page_config(page_title="å°è‚¡æŒ‡æ¨™æ’è¡Œæ¦œ", layout="wide")

@st.cache_data(ttl=3600) # ç·©å­˜ 1 å°æ™‚ï¼Œé¿å…é »ç¹è«‹æ±‚è­‰äº¤æ‰€
def get_safe_tickers():
    url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=15, verify=False)
        response.encoding = 'big5'
        # ä½¿ç”¨å¤šç¨®è§£æå¼•æ“é‡è©¦
        try:
            tables = pd.read_html(response.text, flavor='lxml')
        except:
            tables = pd.read_html(response.text, flavor='html5lib')
            
        df = tables[0]
        df.columns = df.iloc[0]
        df = df[df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±'].str.contains("  ", na=False)]
        # ç¯©é¸æ¨™æº– 4 ç¢¼å°è‚¡
        list_tickers = []
        for item in df['æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±']:
            code = item.split("  ")[0].strip()
            if code.isdigit() and len(code) == 4:
                list_tickers.append(f"{code}.TW")
        return list_tickers
    except Exception as e:
        st.error(f"ç„¡æ³•ç²å–åå–®: {e}")
        return []

def fetch_data_robust(tickers):
    all_results = []
    batch_size = 15 # ç¸®å°æ‰¹æ¬¡æé«˜ç©©å®šæ€§
    p_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i : i + batch_size]
        status_text.text(f"ğŸ“Š æ­£åœ¨åˆ†ææŒ‡æ¨™: {i} / {len(tickers)} ...")
        
        try:
            # è«‹æ±‚ 5 å¤©æ•¸æ“šä»¥é˜²å‡æ—¥ç„¡æ•¸æ“š
            df = yf.download(batch, period="5d", group_by='ticker', threads=False, timeout=20)
            
            for t in batch:
                try:
                    # åˆ¤æ–·å¤šè‚¡ç¥¨ä¸‹è¼‰å¾Œçš„çµæ§‹
                    t_df = df[t].dropna() if isinstance(df.columns, pd.MultiIndex) else df.dropna()
                    
                    if not t_df.empty:
                        last = t_df.iloc[-1]
                        price = float(last['Close'])
                        volume = float(last['Volume'])
                        # æˆäº¤å€¼æŒ‡æ¨™ (å„„)
                        val = round((price * volume) / 100_000_000, 2)
                        
                        if val > 0:
                            all_results.append({
                                "è‚¡ç¥¨ä»£è™Ÿ": t,
                                "æ”¶ç›¤åƒ¹": round(price, 2),
                                "æˆäº¤é‡(å¼µ)": int(volume // 1000),
                                "æˆäº¤é‡‘é¡(å„„)": val,
                                "æˆäº¤å€¼æŒ‡æ¨™": val
                            })
                except: continue
        except:
            st.warning(f"æ‰¹æ¬¡ {i} æŠ“å–è¶…æ™‚ï¼Œè‡ªå‹•è·³é...")
            
        time.sleep(random.uniform(1.2, 2.5)) # éš¨æ©Ÿå»¶é²é é˜²å°é–
        p_bar.progress(min((i + batch_size) / len(tickers), 1.0))
        
    status_text.text("âœ… åˆ†æå®Œæˆ")
    return pd.DataFrame(all_results)

# --- Streamlit ä¸»ä»‹é¢ ---
st.title("ğŸ“Š å°è‚¡æˆäº¤å€¼æŒ‡æ¨™ Top 100 æ’è¡Œæ¦œ")
st.info("æœ¬ç³»çµ±æœƒæƒæå…¨å¸‚å ´ï¼Œä¸¦ä¾æ“šã€Œæˆäº¤å€¼æŒ‡æ¨™ã€ç”±é«˜è‡³ä½æ’åˆ—å‰ 100 åã€‚")

if 'last_run' not in st.session_state:
    st.session_state.last_run = 0

time_diff = time.time() - st.session_state.last_run

if st.button("ğŸš€ é–‹å§‹åŸ·è¡Œå…¨å¸‚å ´ç¯©é¸", type="primary"):
    if time_diff < 300:
        st.error(f"ğŸ›‘ ç³»çµ±å†·å»ä¸­ï¼Œè«‹ç­‰å¾… {int(300 - time_diff)} ç§’ã€‚")
    else:
        st.session_state.last_run = time.time()
        
        with st.status("æ­£åœ¨ç²å–å°è‚¡æ¸…å–®...", expanded=False):
            all_list = get_safe_tickers()
        
        if all_list:
            st.write(f"ğŸ” æˆåŠŸç²å– {len(all_list)} éš»è‚¡ç¥¨ï¼Œé–‹å§‹è¨ˆç®—æŒ‡æ¨™...")
            final_df = fetch_data_robust(all_list)
            
            if not final_df.empty:
                # é—œéµï¼šä¾ç…§æŒ‡æ¨™æ’åºä¸¦å–å‰ 100 å
                top_100 = final_df.sort_values("æˆäº¤å€¼æŒ‡æ¨™", ascending=False).head(100).reset_index(drop=True)
                top_100.index += 1
                
                st.subheader(f"ğŸ† è³‡é‡‘ç†±é» Top 100 ({datetime.now().strftime('%Y-%m-%d')})")
                
                # æ ¼å¼åŒ–é¡¯ç¤º
                try:
                    styled = top_100.style.format({
                        "æ”¶ç›¤åƒ¹": "{:.2f}", 
                        "æˆäº¤é‡‘é¡(å„„)": "{:.2f}", 
                        "æˆäº¤å€¼æŒ‡æ¨™": "{:.2f}"
                    }).background_gradient(subset=['æˆäº¤å€¼æŒ‡æ¨™'], cmap='YlOrRd')
                    st.dataframe(styled, use_container_width=True)
                except:
                    st.dataframe(top_100, use_container_width=True)
                
                csv = top_100.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ“¥ ä¸‹è¼‰æ’è¡Œæ¦œ CSV", data=csv, file_name="TW_Stock_Indicator.csv")
            else:
                st.error("æƒæçµæœç‚ºç©ºï¼Œå¯èƒ½æ˜¯é€£ç·šè¢« Yahoo é˜»æ–·ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
        else:
            st.error("åå–®ç²å–å¤±æ•—ï¼Œè«‹æª¢æŸ¥è­‰äº¤æ‰€é€£ç·šç‹€æ…‹ã€‚")

st.divider()
st.caption("å‚™è¨»ï¼šæ‰€æœ‰æ•¸æ“šå‡å››æ¨äº”å…¥è‡³å°æ•¸é»ç¬¬ 2 ä½ã€‚")
